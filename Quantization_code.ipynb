{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_on_Chips_project_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpBvjvpwA0D1",
        "colab_type": "text"
      },
      "source": [
        "# **SqueezeNet: 8-bit Fixed-point**\n",
        "\n",
        "Steps:\n",
        "1. Implement quantization function from float32 to low-precision in\n",
        "quantization_utils.py\n",
        "2. Run main.py. Get quantized weight, corresponding TF .pb and IR.json\n",
        "3. (debug)Rebuild model with IR.json and quantized weight. Check results layer by layer.\n",
        "4. Evaluate quantized model on ImageNet validation set to check accuracy\n",
        "5. (optional) Retrain quantized model to reduce the accuracy gap compared to original\n",
        "float32 model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfSQ8x90szLI",
        "colab_type": "text"
      },
      "source": [
        "#Setup Enviornment\n",
        "\n",
        "https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html\n",
        "\n",
        "02_TVM_Tutorial_Relay:\n",
        "https://colab.research.google.com/github/uwsampl/tutorial/blob/master/notebook/02_TVM_Tutorial_Relay.ipynb#scrollTo=1cdUL9-QU34l"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot_j8r1ivqMD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9884169-3aad-4a8d-ff49-9f0a867edf86"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "%cd gdrive/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJHHsT7VxrKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torchvision.datasets import ImageNet\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yn_R6BkHmsbu",
        "colab_type": "text"
      },
      "source": [
        "#Quantization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItfxDDxre8Jf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_cuda = True\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "  # net.cuda()\n",
        "  device = torch.device(\"cuda:0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd3ZyvHh_4TM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SqueezeNet(object):\n",
        "\n",
        "    def __init__(self, model_filepath):\n",
        "\n",
        "        # The file path of model\n",
        "        self.model_filepath = model_filepath\n",
        "        # Initialize the model\n",
        "        self.load_graph(model_filepath = self.model_filepath)\n",
        "\n",
        "    def load_graph(self, model_filepath):\n",
        "        '''\n",
        "        Lode trained model.\n",
        "        '''\n",
        "        print('Loading model...')\n",
        "        self.graph = tf.Graph()\n",
        "\n",
        "        with tf.gfile.GFile(model_filepath, 'rb') as f:\n",
        "            graph_def = tf.GraphDef()\n",
        "            graph_def.ParseFromString(f.read())\n",
        "\n",
        "        print('Check out the input placeholders:')\n",
        "        nodes = [n.name + ' => ' +  n.op for n in graph_def.node if n.op in ('Placeholder')]\n",
        "        for node in nodes:\n",
        "            print(node)\n",
        "\n",
        "        with self.graph.as_default():\n",
        "        \t# Define input tensor\n",
        "        \tself.input = tf.placeholder(np.float32, shape = [None,224, 224,3], name='input_fx') \n",
        "        \ttf.import_graph_def(graph_def, {'input_fx': self.input})\n",
        "         \n",
        "\n",
        "        self.graph.finalize()\n",
        "\n",
        "        print('Model loading complete!')\n",
        "        \"\"\"\n",
        "        # Get layer names\n",
        "        layers = [op.name for op in self.graph.get_operations()]\n",
        "        for layer in layers:\n",
        "            print(layer)\n",
        "        \"\"\"\n",
        "        # In this version, tf.InteractiveSession and tf.Session could be used interchangeably. \n",
        "        # self.sess = tf.InteractiveSession(graph = self.graph)\n",
        "        self.sess = tf.Session(graph = self.graph)\n",
        "\n",
        "    def test(self, data):\n",
        "\n",
        "        # Know your output node name\n",
        "        output_tensor = self.graph.get_tensor_by_name(\"import/output_fx:0\")\n",
        "        output = self.sess.run(output_tensor, feed_dict = {self.input: data})\n",
        "\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaWDcIFihz9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PROCESS DATA\n",
        "def preprocess(x):   \n",
        "    '''\n",
        "    Preprocessing required on the images for inference with mxnet gluon\n",
        "    The function takes path to an image and returns processed tensor\n",
        "    '''\n",
        "    transform = transforms.Compose([#[1]\n",
        "                                transforms.Resize(256),#[2]\n",
        "                                transforms.CenterCrop(224),#[3]\n",
        "                                transforms.ToTensor(),#[4]\n",
        "                                transforms.Normalize(#5\n",
        "                                                     mean=[0.485,0.456,0.406],#6\n",
        "                                                     std =[0.229,0.224,0.225] #7\n",
        "                                                    )])\n",
        "    x = x[:,:,::-1]\n",
        "    x = Image.fromarray(x,'RGB')\n",
        "    x = transform(x)\n",
        "    x = tf.transpose(x,perm=[1,2,0])  \n",
        "    x = tf.expand_dims(x,0) # batchify\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IGoXAOHS3Bn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CALCULATING MODEL ACCURACY\n",
        "def model_accuracy(label, prediction):\n",
        "\n",
        "  len_label=len(label)\n",
        "  len_pred =len(prediction)\n",
        "\n",
        "  if( len_label != len_pred):\n",
        "    print(\"Warning: label\"+str(len_label)+\"and prediction\"+ str(len_pred)+\" have unequal lengths!\")\n",
        "   \n",
        "  num_test = min(len_label,len_pred)\n",
        "  count = label[0:num_test+1] == prediction[0:num_test+1]\n",
        "\n",
        "  return np.sum(count)/num_test\n",
        "\n",
        "\n",
        "\n",
        "#LOADING DATA\n",
        "def loading_data(directory, start, batchsize):\n",
        "\n",
        "    # Load and preprocess validation dataset\n",
        "    x_test=[]\n",
        "    filenames = []\n",
        "    counts = 0\n",
        "\n",
        "    tic = time.clock()\n",
        "    \n",
        "    for i in range(start, start+batchsize): #50001)\n",
        "\n",
        "      num_zeros=5-len(str(i))\n",
        "      path = directory+'/ILSVRC2012_val_000'+num_zeros*str(0)+str(i)+'.JPEG'\n",
        "      x = cv2.imread(path)\n",
        "      counts += 1\n",
        "      # print (x)\n",
        "      if x_test == [] :\n",
        "        x_test = preprocess(x)\n",
        "      else:\n",
        "        x_test = tf.concat([x_test,preprocess(x)], axis=0)\n",
        "      \n",
        "      if counts % 100 == 0:\n",
        "        toc = time.clock()\n",
        "        print ('loaded %d images...' %counts, '%5fs'%(toc-tic))\n",
        "        tic = time.clock()\n",
        "\n",
        "    toc = time.clock()\n",
        "    #convert x_test back to numpy\n",
        "    with tf.Session() as sess:  x_test = x_test.eval(session=sess) \n",
        "\n",
        "    #loading y_test from file\n",
        "    lfile = open('/content/gdrive/My Drive/209AS AI on Chips/val.txt')\n",
        "    lines=lfile.readlines()\n",
        "    y_test=[]\n",
        "\n",
        "    for i in lines[start-1:start+batchsize-1]: #zero indexing\n",
        "      y_test.append(int(i.split(' ')[-1]))\n",
        "    \n",
        "    print('loaded %d labels' %len(y_test))\n",
        "    \n",
        "    return x_test, np.array(y_test)\n",
        "\n",
        "\n",
        "#PREDICTION\n",
        "def test_from_frozen_graph(x_test, y_test):\n",
        "\n",
        "    tf.reset_default_graph()\n",
        "\n",
        "    test_prediction_onehot = model.test(data = x_test)\n",
        "    test_prediction = np.argmax(test_prediction_onehot, axis = 3).reshape((-1))\n",
        "    test_accuracy = model_accuracy(label = y_test, prediction = test_prediction)\n",
        "    return test_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1_5VKGxUEL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Wrapper function\n",
        "def Evaluation(start, batch_size, directory):\n",
        "\n",
        "    x_test,y_test = loading_data(directory,start,batchsize) #preprocess and return x, read y \n",
        "    accuracy = test_from_frozen_graph(x_test, y_test)\n",
        "    print('Tested %d images,' %batch_size, 'Accuracy = %f' %(accuracy*100), '%')\n",
        "\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zqprYhkiF_J",
        "colab_type": "text"
      },
      "source": [
        "## evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVWiAHi3id8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# accuracies, loaded_files = Evaluation(filesindir, accuracies, loaded_files, 3, 10000, '/content/gdrive/My Drive/UCLA/AI on Chips/val_dataset')\n",
        "model = SqueezeNet('/content/gdrive/My Drive/209AS AI on Chips/test_m1.pb') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20X_kwkPtQUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loaded_files, accuracies = [], []\n",
        "\n",
        "start = 1\n",
        "batchsize = 100\n",
        "\n",
        "while( start + batchsize <= 1101):\n",
        "  print(\"Start: \" + str(start))\n",
        "  accuracy = Evaluation(start, batchsize,'/content/gdrive/My Drive/209AS AI on Chips/valset')\n",
        "\n",
        "  with open('/content/gdrive/My Drive/209AS AI on Chips/resultlog_m1.txt', 'a') as output:\n",
        "\n",
        "    output.write('Start:'+str(start)+' Stop:'+str(start+batchsize)+ ' batchsize: ' +str(batchsize)+'\\n' )\n",
        "    output.write(str(accuracy) + '\\n')\n",
        "\n",
        "  print()\n",
        "  start = start + batchsize\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LB0BCJpHJNm2",
        "colab_type": "text"
      },
      "source": [
        "# Code for Quantization_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xX_hbNcV0lwr",
        "colab_type": "text"
      },
      "source": [
        "##prime method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2L3DfRbJN22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import math\n",
        "# '''\n",
        "# utility function\n",
        "# with with block.suppress_stdout_stderr():\n",
        "#     your code\n",
        "# To hide stdout/stderr output i.e. from Tensorflow initialzation    \n",
        "# '''\n",
        "# from . import suppress_stdout_stderr as block\n",
        "\n",
        "\n",
        "def tf_symbolic_convert(value, wl, fl):\n",
        "    '''\n",
        "    Convert float numpy array to wl-bit low precision data with Tensorflow API\n",
        "    \n",
        "    Inputs：\n",
        "    - value : a numpy array of input data\n",
        "    - wl : word length of the data format to convert\n",
        "    - fl : fraction length (exponent length for floating-point)\n",
        "    \n",
        "    Returns:\n",
        "    - val_fp : tf.Tensor as the symbolic expression for quantization \n",
        "    '''\n",
        "\n",
        "    max_v = 0\n",
        "    for i in range(int(wl-1),0, -1):\n",
        "      max_v +=2**(i-fl-1)\n",
        "    \n",
        "    print ('max_value:', max_v, 'min_value:', -max_v)\n",
        "    value = tf.convert_to_tensor(value)\n",
        "    values_sign = tf.sign(value)\n",
        "\n",
        "    val_fp = tf.abs(value)\n",
        "    val_fp = tf.floor(val_fp)*values_sign\n",
        "\n",
        "    values_frac = tf.abs(value)-tf.abs(val_fp)\n",
        "    \n",
        "    for i in range(fl):\n",
        "      binary_base = 2**-(i+1)\n",
        "      values_frac = values_frac * 2\n",
        "      select = tf.greater_equal(values_frac, 1)\n",
        "      select = tf.cast(select, value.dtype)\n",
        "      values_frac = values_frac - select\n",
        "      val_fp = val_fp + select * binary_base * values_sign\n",
        "      \n",
        "\n",
        "    remaining = tf.greater_equal(tf.abs(value-val_fp), 2**-(fl+1))\n",
        "    remaining = tf.cast(remaining, value.dtype)\n",
        "    \n",
        "    val_fp = val_fp + remaining * 2**-fl * values_sign\n",
        "    val_fp=tf.clip_by_value(val_fp, -max_v, max_v)\n",
        "    print (val_fp.eval(session=tf.Session()))\n",
        "\n",
        "    return val_fp\n",
        "\n",
        "class Qnn:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    # dtype convertion: basic functions           \n",
        "    def to_fixedpoint(self, data_i, word_len, frac_len):\n",
        "        return tf_symbolic_convert(data_i, word_len, frac_len)\n",
        "    \n",
        "    # utility function to convert symbolically or numerically\n",
        "    def convert(self, data_i, word_len, frac_len, symbolic=False):\n",
        "        if symbolic is True:\n",
        "            data_q = self.to_fixedpoint(data_i, word_len, frac_len)\n",
        "        else:\n",
        "            with tf.Graph().as_default():\n",
        "                data_q = self.to_fixedpoint(data_i, word_len, frac_len)\n",
        "                with block.suppress_stdout_stderr():\n",
        "                with tf.Session() as sess:\n",
        "                    data_q = sess.run(data_q)\n",
        "        return data_q    \n",
        "        \n",
        "    # error measurement\n",
        "    def difference(self, data_q, data_origin):    \n",
        "        '''\n",
        "        Compute the difference before and after quantization\n",
        "        \n",
        "        Inputs：\n",
        "        - data_q: a numpy array of quantized data\n",
        "        - data_origin: a numpy array of original data\n",
        "        \n",
        "        Returns:\n",
        "        - dif : numerical value of quantization error \n",
        "        '''\n",
        "  \n",
        "        dif= np.sum((data_q - data_origin)**2)\n",
        "\n",
        "        return dif\n",
        "    \n",
        "    # search policy\n",
        "    def search(self, data_i, word_len):\n",
        "        '''\n",
        "        Search for the optimal fraction length that leads to minimal quantization error for data_i\n",
        "        \n",
        "        Inputs：\n",
        "        - data_i : a numpy array of original data\n",
        "        - word_len : word length of quantized data\n",
        "        \n",
        "        Returns:\n",
        "        - fl_opt : fraction length (python built-in int data type) that leads to minimal quantization error\n",
        "        '''\n",
        "        \n",
        "        error = []\n",
        "        frac_len = range(word_len)\n",
        "        for f in frac_len:\n",
        "          print ('frac_len = %d'%f)\n",
        "          data = self.convert(data_i, word_len, f, symbolic=False)\n",
        "          error.append(self.difference(data, data_i))\n",
        "        \n",
        "        print ('errors:', error)\n",
        "        max_index = error.index(min(error))\n",
        "        fl_opt = frac_len[max_index]\n",
        "        print ('best fraction_length = %d' %fl_opt)\n",
        "       \n",
        "        return fl_opt\n",
        "    \n",
        "    # granularity\n",
        "    def apply(self, data_i, word_len):\n",
        "        fl_opt = self.search(data_i, word_len)\n",
        "        data_q = self.convert(data_i, word_len, fl_opt)\n",
        "        return data_q, fl_opt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LClX3gs70pAU",
        "colab_type": "text"
      },
      "source": [
        "##Method 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uwHTcsT0wzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tf_symbolic_convert_m1(value, wl, fl):\n",
        "  max_v = 0\n",
        "  for i in range(int(wl-1),0, -1):\n",
        "    max_v +=2**(i-fl-1)\n",
        "  \n",
        "  print ('max_value:', max_v, 'min_value:', -max_v)\n",
        "  \n",
        "  # values_sign = np.sign(value)\n",
        "  min_value = np.min(value)\n",
        "  print ('min_value of data = ', min_value, ', max value = ', min_value + max_v)\n",
        "  quantize_step = 2**-fl\n",
        "  print ('quantized step = ', quantize_step)\n",
        "  \n",
        "  choose = value >= (min_value + max_v)\n",
        "  value[choose] = min_value + max_v\n",
        "    \n",
        "  val_fp = (value - min_value)/quantize_step\n",
        "  \n",
        "  #get integer part\n",
        "  select = val_fp - np.floor(val_fp)\n",
        "  select = select >= 0.5\n",
        "  val_fp = np.floor(val_fp) + select * 1\n",
        "  val_fp = val_fp * quantize_step + min_value\n",
        "  print(val_fp)\n",
        " \n",
        "\n",
        "\n",
        "  return val_fp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6MkMjNFkyUA",
        "colab_type": "text"
      },
      "source": [
        "## testing the code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kUdXWLiVOUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = np.array([[1.345987, 20.3459874, 13.348574],[-8.230975, -13.835, 28.4842],[3.65489, 21.376, 28.4542],[3.648, -21.50975, 13.027395],[3.3430985, 21.875, -13.027395]])\n",
        "x = Qnn()\n",
        "print('random numpy input:\\n', A)\n",
        "print()\n",
        "x.search(data_i=A, word_len=8)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}